{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Shared Task 4\n",
    "This Notebook is designed to be used in **Google Colab!**\n",
    "\n",
    "You will gain points in this task by competing on a leaderboard on two tasks and also by implementing some simple functions in this notebook. The two task for which you are competing are:   \n",
    "1) **closed track**: each team should use a pre-defined LLM (Mistral) to design prompts (simple one or complex\n",
    "one) to perform the two tasks defined in subtask 3, and submit the best 3 predictions of the testing instances\n",
    "\n",
    "2) **open track**: each team can use any LLMs (e.g., GPT-4) or the trained model from subtask 3 to perform the task\n",
    "and submit the best 3 predictions of the testing instances.\n",
    "\n",
    "You will get a refresher on how to prompt a model over API, but also learn how to prompt a model running locally in Google Colab. You will develop and evaluate your prompts on the dev dataset and then submit the results of your prompts / models on the test dataset."
   ],
   "metadata": {
    "id": "Fz_Ta7yBW1wt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip -q install bitsandbytes accelerate xformers einops langchain\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import accelerate\n",
    "import math\n",
    "from langchain import PromptTemplate, LLMChain, HuggingFacePipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ],
   "metadata": {
    "id": "NTTj1c61cYQt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704640274885,
     "user_tz": -60,
     "elapsed": 232761,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    },
    "outputId": "9badd7d6-f5ac-4647-b0e2-45ede2e67cc4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DX4UJ1ftcoZm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704640623064,
     "user_tz": -60,
     "elapsed": 348200,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    },
    "outputId": "6a2c374a-2e71-44fe-fb88-1918a393a4f8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LLMs as an Evaluator\n",
    "The goal in this section is, to use the LLM 'Mistral' as an Evaluator for other LLMs. You should try to prompt the LLM with two prompts, one employing CoT, while the other does not. In the end you can compare the two prompts by calculating Precision, Recall and F1 Score."
   ],
   "metadata": {
    "collapsed": false,
    "id": "_7pLwQ-kcYQv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following cell you access to prompting Mistral as you learned in Tutorial 6"
   ],
   "metadata": {
    "collapsed": false,
    "id": "mUNTWFdFcYQw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "HF_API_TOKEN: str = open(\"/content/drive/MyDrive/Colab Notebooks/Folt/subtask4/HF_TOKEN\", 'r').read().strip()\n",
    "client = InferenceClient(token=HF_API_TOKEN, timeout=300)"
   ],
   "metadata": {
    "id": "TUG_w7QNcYQx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704640623874,
     "user_tz": -60,
     "elapsed": 816,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def inference(text: str, max_new_tokens: int = 20, wait_btwn_prompts: float = 0.1):\n",
    "    \"\"\"\n",
    "    text: str\n",
    "        Text to use for inference.\n",
    "    max_new_tokens: int\n",
    "        Maximum number of tokens to generate.\n",
    "    \"\"\"\n",
    "    time.sleep(wait_btwn_prompts)\n",
    "\n",
    "    output = client.text_generation(\n",
    "        text,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "\n",
    "    )\n",
    "    return output.removeprefix(\" \")"
   ],
   "metadata": {
    "id": "jmWv7kV3cYQz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704640623875,
     "user_tz": -60,
     "elapsed": 4,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following cells, we will setup the local model. Feel free to try and understand the setup, but you can also just use the inference as is."
   ],
   "metadata": {
    "id": "3VSaLPSMYlSJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "      model_name,\n",
    "      quantization_config=bnb_config,\n",
    "      device_map=\"auto\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "4667953b59834f77ab752acfc60f4be2",
      "dbbdde4600a34153b25fd383a383b674",
      "9589f99254924e65881a147d52497cc6",
      "f61444b14d2f4791b12d885821a84d15",
      "448d460981ba4b3ca5e8fe787a70dc58",
      "7c22ee51a1d549f7be198badffbb8201",
      "e70d9fb027624bdc9773c1a7d4620db3",
      "793ddd5daa2147b5bde405c8cfad62a9",
      "729be875f4fc47239fbdeb417e3145b3",
      "69d81e0a6c994e61af6039282ac58bd2",
      "0984b4dd31db444abd598882520ca385",
      "1424933e49ca43809d1cc9a2fb364907",
      "d11c3ca5564c40c28a4130c5ed01363f",
      "a638d490065c4b9c87229975429f4960",
      "4262f208fc8148a8949641b25080efc3",
      "b8b8c270e9f64380a01e33702b7eccdf",
      "09b056580e1c4723b592e151ad6e7135",
      "701509105ae340c9ac3afc824f9f55e7",
      "76c7e443d9214295bd9f7a06a5b5c6a8",
      "51da62af8a1644aa8c2a121b1c6095c3",
      "7a398de6f4dc409ea30f1187d32af596",
      "95064a61a6174af5a927018f734e55e2",
      "d46898df51d14b91a5c552ecdbdc1748",
      "79250251f6ef43d88b6199641398bdbe",
      "f50d293dfad2489f87943058f3800da4",
      "c0f5136d79574cd085ca28477585fb40",
      "a0640be91cf44e928eef22ee7e2943e9",
      "740320c045a346bab76b931e425d9ef3",
      "20707524e7f541b0a0769113bfe777f9",
      "8d138ebcea264ca985c126cd7586b190",
      "796bb8d0947e48ab9ea5eab875c4adf4",
      "d9bd1ac7702a46c398282edf3aca89de",
      "216d247520764019b60b9ce4c9218671",
      "244a2085543f47ae86ee53b9ce274ecb",
      "50e140f0a23b4dd9aebe2e5dfc4b50c6",
      "d7a6322396064ec78aea951d0eca77d4",
      "3bff03adfadf4eb880f92b30340de2b3",
      "ed2ac3d94ba446dead80817cc3121a9c",
      "84fc16c60f004b58854c15544ab98dca",
      "06a21b9d104648488243afec2d32d0fa",
      "98ac14333666490f986962e1d749aa23",
      "22c739513f6741a88ded38ed428a7842",
      "86543498f31c4b79a7a8717e5cd0ccf2",
      "332c88ecd3b648c1bb0a691b258e0978"
     ]
    },
    "id": "PmoAC6f6cYQx",
    "outputId": "01bd1592-f8a4-414a-ad43-665d728d0ee9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    do_sample=True,\n",
    "    max_new_tokens=10,\n",
    "    top_k=5,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    "    )"
   ],
   "metadata": {
    "id": "6A-bKZK62NeL",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891559,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ],
   "metadata": {
    "id": "h4Jci4Es7vAy",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891559,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def local_inference(llm_chain, args):\n",
    "  \"\"\"\n",
    "  llm_chain: LLMChain\n",
    "        The LLMChain to be used for prompting\n",
    "    args: dict or list(dict)\n",
    "        A dict or a list of dicts which contain the input data, which is to be inserted in the placeholders in the llm chain.\n",
    "  \"\"\"\n",
    "  if type(args) == list:\n",
    "    ans = llm_chain.batch(args)\n",
    "  else:\n",
    "    ans = llm_chain.run(args)\n",
    "  return ans"
   ],
   "metadata": {
    "id": "Yh5GvbyrcYQ0",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891559,
     "user_tz": -60,
     "elapsed": 8,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following cell gives you some example prompts, which you can use to develop your own Prompts for Evaluation. Keep in mind, that you want to complete both tasks of subtask 3 again, but this time using prompting. The following examples are only for the first task."
   ],
   "metadata": {
    "collapsed": false,
    "id": "NZJNoZWJcYQ1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Question = \"Example Question\"\n",
    "LLM_A = \"Hello I'm not human\"\n",
    "GOLD_A = \"Hello I'm human\"\n",
    "\n",
    "simple_prompt = f\"[INST]Which of the following Answers (A) is more fit for the provided Question (Q). Provide you Verdict in the Format of 'Verdict: A'. Q:'{Question}' A1: '{LLM_A}', A2: '{GOLD_A}'[/INST]\"\n",
    "\n",
    "cot_prompt = f\"<s> [INST]Which of the following Answers (A) is more fit for the provided Question (Q). Provide you Verdict in the Format of 'Verdict: A'. Q:'The sky is blue.' A1: 'Thats wrong.', A2: 'Thats true.'[/INST] Verdict: A1</s> [INST]Which of the following Answers (A) is more fit for the provided Question (Q). Q:'{Question}' A1: '{LLM_A}', A2: '{GOLD_A}'[/INST]\""
   ],
   "metadata": {
    "id": "3cDKgNkBcYQ1",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891559,
     "user_tz": -60,
     "elapsed": 8,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generally you can think of this scheme for using prompting to evaluate for this task, but also have in mind, that you already learned CoT prompting. Feel free to try out all sorts of prompts!\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "sGWbZv97cYQ1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1\n",
    "input – tuple(question, gold answer, LLM answer)   \n",
    "output – prediction whether LLM answer is harmful or non-harmful"
   ],
   "metadata": {
    "collapsed": false,
    "id": "SWaX44g5cYQ2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building some prompts\n",
    "Let's start by building the prompts, you want to use for evaluating the first task."
   ],
   "metadata": {
    "collapsed": false,
    "id": "Xp3FZnEBcYQ2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_complex_prompt_t1():\n",
    "    #TODO:THIS IS AN EXAMPLE HOW LOCAL PROMPTING WORKS\n",
    "    #YOUR PROMPT HERE\n",
    "    text = \"<s> [INST]Which of the following Answers (A) is more fit for the provided Question (Q). Provide you Verdict in the Format of 'Verdict: A'. Q:'The sky is blue.' A1: 'Thats wrong.', A2: 'Thats true.'[/INST] Verdict: A1</s> [INST]Which of the following Answers (A) is more fit for the provided Question (Q). Q:'{question}' A1: '{llm_a}' A2: '{gold_a}'[/INST]\"\n",
    "    #YOUR PROMPT HERE\n",
    "    prompt = PromptTemplate(template=text, input_variables=[\"question\",\"llm_a\", \"gold_a\"])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    return llm_chain"
   ],
   "metadata": {
    "id": "efkd36nlcYQ3",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891560,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_simple_prompt_t1():\n",
    "    #YOUR PROMPT HERE\n",
    "    text = \"\"\n",
    "    #YOUR PROMPT HERE\n",
    "    prompt = PromptTemplate(template=text, input_variables=[\"question\",\"llm_a\", \"gold_a\"])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    return llm_chain"
   ],
   "metadata": {
    "id": "fmlv_wt7cYQ3",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891560,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next up we'll need to load the data from your annotated json"
   ],
   "metadata": {
    "collapsed": false,
    "id": "N32kBxoTcYQ3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_data(path):\n",
    "    '''\n",
    "    Extracts information from the annotation JSON file containing cca_llm_answers.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, each containing information about a QA pair.\n",
    "              Each tuple includes the following elements:\n",
    "              - Question type\n",
    "              - LLM model name\n",
    "              - Topic 1 (list of strings)\n",
    "              - Topic 2 (list of strings)\n",
    "              - Labels (list of strings)\n",
    "              - Question text\n",
    "              - Gold answer text\n",
    "              - LLM answer text\n",
    "    '''\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        cca_llm_answers = json.load(file)\n",
    "        annotation_entries = []\n",
    "\n",
    "    for qa_pair in cca_llm_answers:\n",
    "        #id = cca_llm_answer[\"id\"]\n",
    "        llm_model = qa_pair[\"data\"][\"llm_model_name\"][:-7]\n",
    "        topic_1 = qa_pair[\"data\"][\"topic1\"][1:-1].replace(\"'\", \"\").split(\", \")\n",
    "        topic_2 = qa_pair[\"data\"][\"topic2\"][1:-1].replace(\"'\", \"\").split(\", \")\n",
    "        question = qa_pair[\"data\"][\"question\"].replace('\\n', '')\n",
    "        gold_answer = qa_pair[\"data\"][\"gold_answer\"].replace('\\n', '')\n",
    "        llm_answer = qa_pair[\"data\"][\"llm_answer\"].replace('\\n', '')\n",
    "        # we initalize the values as an empty string or an empty list\n",
    "        question_type, labels = \"\", []\n",
    "\n",
    "        # we iterate through the entries of the values to extract validity, question_type and the labels\n",
    "        for answer_unit in qa_pair[\"annotations\"][0][\"result\"]:\n",
    "            if answer_unit[\"type\"] == \"labels\":\n",
    "                # Extracting labels and handling the case where labels are not present\n",
    "                labels.append(answer_unit[\"value\"].get(\"labels\", [\"\"])[0])\n",
    "            elif answer_unit[\"type\"] == \"choices\" and answer_unit[\"origin\"] == \"manual\":\n",
    "                question_type = answer_unit[\"value\"][\"choices\"][0]\n",
    "\n",
    "        # appending the tuple of information for this qa_pair\n",
    "        annotation_entries.append(\n",
    "            (question_type, llm_model, topic_1, topic_2, labels, question, gold_answer, llm_answer)\n",
    "        )\n",
    "    return annotation_entries"
   ],
   "metadata": {
    "id": "dXdquNTqcYQ4",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891560,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the extracted data, we build a proper feature set."
   ],
   "metadata": {
    "collapsed": false,
    "id": "TDxe0BoecYQ4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_feature_set(data):\n",
    "    '''\n",
    "    Create a feature set for training/test data consisting of the question, the gold answer and the LLM answer.\n",
    "\n",
    "    Args:\n",
    "        data(list of tuples): the extracted data from the function extract_data.\n",
    "\n",
    "    Returns:\n",
    "        list: Feature set, where each entry is a tuple with a feature dictionary and its label.\n",
    "    '''\n",
    "    feature_set = []\n",
    "    for qa_pair in data:\n",
    "        # assign the label, it is harmful if it is either Contradiction or Exaggeration\n",
    "        label = \"\"\n",
    "        if qa_pair[4] != \"\":\n",
    "            label = \"harmful\" if \"Contradiction\" in qa_pair[4] or \"Exaggeration\" in qa_pair[4] else \"non_harmful\"\n",
    "        # Create a dictionary with the relevant features.\n",
    "        feature_dict = {\"question\": qa_pair[5], \"gold_answer\": qa_pair[6], \"llm_answer\": qa_pair[7]}\n",
    "        feature_set.append((feature_dict, label))\n",
    "\n",
    "    return feature_set"
   ],
   "metadata": {
    "id": "BDSPH4D0cYQ4",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891560,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_set_t1 = create_feature_set(extract_data(\"dev.json\"))"
   ],
   "metadata": {
    "id": "8dxtc0cwcYQ5",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891560,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can use the following methods, if you are running into problems with colab or your local notebook, to cache the data incase the notebook times out"
   ],
   "metadata": {
    "id": "JeViLABlaA8h"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cache_data(data, i, pred_gold_dict):\n",
    "    '''\n",
    "    Caches the data in case of a catastrophic problem. (e.g. The api stops responding). Caches the data and sets the name of the file to be the iteration it crashed.\n",
    "    :param data: Already predicted labels\n",
    "    :return:\n",
    "    '''\n",
    "    if \"simple\" in pred_gold_dict.keys(): pred_gold_dict[\"cached_complex\"] = data\n",
    "    else: pred_gold_dict[\"cached_simple\"] = data\n",
    "\n",
    "    if \"cached\" not in os.listdir(\".\"):\n",
    "        os.mkdir(\"cached\")\n",
    "\n",
    "    with open(f\"cached/{i}.txt\", \"wb\") as data:\n",
    "        pickle.dump(pred_gold_dict, data)"
   ],
   "metadata": {
    "id": "v7FMAMPLZ6ul",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891560,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_cached_data()->tuple:\n",
    "    '''\n",
    "    Loads the cached data from a previous run\n",
    "    :return: Cached Data and the iteration it crashed (i, dict(data))\n",
    "    '''\n",
    "\n",
    "    files = os.listdir(\"cached/\")\n",
    "    def sort_by_no(s:str):\n",
    "        return int(s[:-4])\n",
    "\n",
    "    files.sort(key=sort_by_no)\n",
    "    last_step = \"cached/\"+files[-1]\n",
    "\n",
    "    with open(last_step, \"rb\") as data:\n",
    "        return int(files[-1][:-4]), dict(pickle.load(data))\n"
   ],
   "metadata": {
    "id": "Upb5BzWVZ6up",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891560,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extracting the Verdict\n",
    "Think about your prompt and what answer the LLM gives, do you need to preprocess the Answer?\n",
    "Hint:\n",
    "- Remember that you can prompt the LLM in such a way, that this task may become trivial."
   ],
   "metadata": {
    "collapsed": false,
    "id": "S034k_dQcYQ5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_verdict_t1(pred: str) -> str:\n",
    "    '''\n",
    "    Extracts the textual verdict and returns the index of the favoured answer. Remember that you can prompt the LLM in such a way, that this task may become trivial.\n",
    "    :param evaluation: The evaluation text of the LLM Evaluator\n",
    "    :return: index of favoured answer\n",
    "    '''\n",
    "    verdict = \"No verdict\"\n",
    "    # YOUR CODE HERE\n",
    "    # YOUR CODE HERE\n",
    "    return verdict"
   ],
   "metadata": {
    "id": "2031SdDDcYQ5",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891560,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prompting the LLM and gaining the label\n",
    "Now we'll get to the actual prompting and extracting a label from the answer."
   ],
   "metadata": {
    "collapsed": false,
    "id": "jyfjhbWscYQ5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prompting_model_t1(llm_chain, arg_dict) -> list:\n",
    "\n",
    "    result = local_inference(llm_chain, arg_dict)\n",
    "    result = extract_verdict_t1(result)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "id": "PN4upTcpcYQ5",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891560,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_task1(prompts: list) -> dict:\n",
    "    \"\"\"\n",
    "    :param prompts: What prompts to use in the tasks (e.g. [\"simple\"])\n",
    "    :return: prediction labels for all the prompts and all ccas\n",
    "    \"\"\"\n",
    "    all_preds = {}\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    return all_preds"
   ],
   "metadata": {
    "id": "H4qD7X1QcYQ6",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704639891561,
     "user_tz": -60,
     "elapsed": 10,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_predictions = predict_task1([\"simple\"])\n",
    "assert type(test_predictions) == dict\n",
    "assert len(test_predictions.keys()) == 1\n",
    "assert len(test_predictions[\"simple\"]) == len(feature_set_t1) \n",
    "assert set(test_predictions[\"simple\"]) == {\"harmful\", \"non_harmful\"}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_t1 = predict_task1([\"complex\", \"simple\"])"
   ],
   "metadata": {
    "id": "XS1_-_CMcYQ6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1704639493786,
     "user_tz": -60,
     "elapsed": 1461496,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    },
    "outputId": "e42e67fd-a710-496a-ab72-9b38ec22cb36"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 2\n",
    "In the second task we will take in a tuple consisting of a question, a gold answer and a LLM answer unit as input and they will predict the label of the LLM answer unit (6 categories). The categories being: **Contradiction, Exaggeration, Understatement, Agree with gold answer, Cannot assess, General comment.**   \n",
    "input – tuple(question, gold answer, LLM answer, LLM answer unit i)   \n",
    "output – predict the category of LLM answer unit i (6 categories)"
   ],
   "metadata": {
    "collapsed": false,
    "id": "pSiHfau9cYQ6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_llm_answer(path):\n",
    "    '''\n",
    "    Returns a feature dataset from a JSON file containing the features: question, gold answer and the LLM answer units as well as their labels.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    - List[Tuple[Dict[str, str], str]]: A list of tuples containing the features and the label.\n",
    "      Each tuple consists of a dictionary with \"questions\", \"gold_answer\", and \"llm_answer_unit\",\n",
    "      and a label string.\n",
    "    '''\n",
    "    # Read the JSON file\n",
    "    with open(path,\"r\", encoding=\"utf-8\",) as file:\n",
    "        cca_llm_answers = json.load(file)\n",
    "        annotation_entry = []\n",
    "\n",
    "    # Extract the required information from each entry in the JSON file\n",
    "    for cca_llm_answer in cca_llm_answers:\n",
    "        question = cca_llm_answer[\"data\"][\"question\"].replace('\\n', '')\n",
    "        gold_answer = cca_llm_answer[\"data\"][\"gold_answer\"].replace('\\n', '')\n",
    "\n",
    "        for qa_pair in cca_llm_answer[\"annotations\"][0][\"result\"]:\n",
    "\n",
    "                if qa_pair[\"type\"] == \"labels\":\n",
    "                    label = qa_pair[\"value\"].get(\"labels\", [\"\"])[0]\n",
    "                    llm_answer_unit = qa_pair[\"value\"].get(\"text\")\n",
    "                    # Add the extracted information to the list\n",
    "                    annotation_entry.append(({\"question\":question, \"gold_answer\": gold_answer, \"llm_answer_unit\": llm_answer_unit}, label))\n",
    "\n",
    "\n",
    "    return annotation_entry"
   ],
   "metadata": {
    "id": "9eDKG_18cYQ6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704636168247,
     "user_tz": -60,
     "elapsed": 437,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_set_t2 = extract_llm_answer(\"dev.json\")"
   ],
   "metadata": {
    "id": "U8w6DUL7cYQ6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704636169713,
     "user_tz": -60,
     "elapsed": 374,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_complex_prompt_t2():\n",
    "    # [\"Contradiction\", \"Exaggeration\", \"Understatement\", \"Agree with gold answer\", \"Cannot assess\", \"General comment\"]\n",
    "    #YOUR PROMPT HERE\n",
    "    text = \"\"\n",
    "    #YOUR PROMPT HERE\n",
    "    prompt = PromptTemplate(template=text, input_variables=[\"question\",\"llm_answer_unit\", \"gold_a\"])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    return llm_chain"
   ],
   "metadata": {
    "id": "TLehOJnBcYQ6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704636250522,
     "user_tz": -60,
     "elapsed": 343,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_simple_prompt_t2():\n",
    "    # [\"Contradiction\", \"Exaggeration\", \"Understatement\", \"Agree with gold answer\", \"Cannot assess\", \"General comment\"]\n",
    "    #YOUR PROMPT HERE\n",
    "    text = \"\"\n",
    "    #YOUR PROMPT HERE\n",
    "    prompt = PromptTemplate(template=text, input_variables=[\"question\",\"llm_answer_unit\", \"gold_a\"])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    return llm_chain"
   ],
   "metadata": {
    "id": "aGLwTXrEcYQ7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704636251525,
     "user_tz": -60,
     "elapsed": 1,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_verdict_t2(result: str):\n",
    "    '''\n",
    "    Extract the verdict of the result, if it doesn't already fit the right format\n",
    "    :param result: Original result\n",
    "    :return: extracted and cleaned up label\n",
    "    '''\n",
    "    #[\"Contradiction\", \"Exaggeration\", \"Understatement\", \"Agree with gold answer\", \"Cannot assess\", \"General comment\"]\n",
    "    verdict = \"No verdict\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return verdict"
   ],
   "metadata": {
    "id": "u0R0qZYMcYQ7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704636009127,
     "user_tz": -60,
     "elapsed": 694,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prompting_model_t2(llm_chain, q, llm_a_unit, gold_a) -> int:\n",
    "    result = local_inference(llm_chain, {\"question\":q,\"llm_answer_unit\":llm_a_unit, \"gold_a\":gold_a})\n",
    "    result = extract_verdict_t2(result)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "id": "TquTNJTrcYQ7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704636255619,
     "user_tz": -60,
     "elapsed": 416,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_task2(prompts: list) -> dict:\n",
    "    \"\"\"\n",
    "    :param prompts: What prompts to use in the tasks (e.g. [\"simple\"])\n",
    "    :return: prediction, gold label set for every combination of prompt and task\n",
    "    \"\"\"\n",
    "    all_preds = {}\n",
    "    start_time = time.time()\n",
    "    torch.cuda.empty_cache()\n",
    "    chains = {\n",
    "        \"complex\" : build_complex_prompt_t2(),\n",
    "        \"simple\" : build_simple_prompt_t2()\n",
    "    }\n",
    "    len_all_answers = len(feature_set_t2) * len(prompts)\n",
    "\n",
    "    for p in prompts:\n",
    "        predictions = []\n",
    "        chain = chains[p]\n",
    "\n",
    "        for i, cca in enumerate(feature_set_t2):\n",
    "            q = cca[0][\"question\"]\n",
    "            llm_a_unit = cca[0][\"llm_answer_unit\"]\n",
    "            gold_a = cca[0][\"gold_answer\"]\n",
    "            \n",
    "            pred = prompting_model_t2(chain, q, llm_a_unit, gold_a)\n",
    "            \n",
    "            if i % 5 == 0: print(\"Elapsed time(min): {:.2f}\".format((time.time() - start_time)/60))\n",
    "            print(\"{:}/{:}: \".format(i + 1, len_all_answers) ,  \"\\t Prediction: \", pred, \"\\t Gold Labels: \", cca[1])\n",
    "            predictions.append(pred)\n",
    "        all_preds[p] = predictions\n",
    "        \n",
    "    return all_preds"
   ],
   "metadata": {
    "id": "JBYPJUc8cYQ7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1704636284930,
     "user_tz": -60,
     "elapsed": 403,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_t2 = predict_task2([\"complex\", \"simple\"])"
   ],
   "metadata": {
    "id": "g5Z6nJrRcYQ7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating the Model\n",
    "Compute the Precision, Recall and the F1 Score in order to gain insights into the differences of the two prompting techniques."
   ],
   "metadata": {
    "collapsed": false,
    "id": "zjD-WyJrcYQ8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ],
   "metadata": {
    "id": "Z7k_VAvpcYQ8",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704635929341,
     "user_tz": -60,
     "elapsed": 4,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_metrics(gold_standard, preds, pos_label = 1, labels = None, average=\"binary\"):\n",
    "    '''\n",
    "    Computes the Precision, Recall and F1 Score of the verdicts\n",
    "    :param gold_standard: The gold standard labels\n",
    "    :param verdicts: The verdicts of Mistral\n",
    "    :return: Precision, Recall and F1 Score of the verdicts\n",
    "    '''\n",
    "    p = 0.0\n",
    "    r = 0.0\n",
    "    f = 0.0\n",
    "    acc = 0.0\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return p, r, f, acc"
   ],
   "metadata": {
    "id": "HpZmdOW6cYQ8",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704635929341,
     "user_tz": -60,
     "elapsed": 4,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_golds = [1,0,0,0,1,1,1,1]\n",
    "test_preds = [1,0,0,0,0,0,0,0]\n",
    "t_p, t_r, t_f, t_acc = calculate_metrics(test_golds, test_preds)\n",
    "assert t_p == 1\n",
    "assert t_r == 0.2\n",
    "assert math.isclose(t_f, 0.33, abs_tol=0.01)\n",
    "assert t_acc == 0.5"
   ],
   "metadata": {
    "id": "o8U2R-5dcYQ8",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1704635929341,
     "user_tz": -60,
     "elapsed": 4,
     "user": {
      "displayName": "Lukas Rohde",
      "userId": "02794772417508370394"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use the above function to evaluate your prompts and make a decision on what to submit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submitting your results\n",
    "As you already know, you can submit three prediction files for both the closed and open track exercises. As both of them include the two tasks, that means you can submit a total of **12** files, lastly you need to include a short text file, describing the models or prompts you used. If you want to submit less that's also fine. Put all your files in a .zip file and upload it to moodle by **Feb 9**. Your Submission should look something like this:\n",
    "\n",
    "The csv contains two rows: \n",
    "CCA-LLM-Answer-ID, Prediction\n",
    "10-1002_cca-4086_ChatGPT_prompt0_answer, students' prediction\n",
    "\n",
    "team_no_closed_track_task1_prediction1.csv\n",
    "team_no_closed_track_task1_prediction2.csv\n",
    "team_no_closed_track_task1_prediction3.csv\n",
    "team_no_closed_track_task2_prediction1.csv\n",
    "team_no_closed_track_task2_prediction2.csv\n",
    "team_no_closed_track_task2_prediction3.csv\n",
    "team_no_open_track_task1_prediction1.csv\n",
    "team_no_open_track_task1_prediction2.csv\n",
    "team_no_open_track_task1_prediction3.csv\n",
    "team_no_open_track_task2_prediction1.csv\n",
    "team_no_open_track_task2_prediction2.csv\n",
    "team_no_open_track_task2_prediction3.csv\n",
    "ModelDescription.txt (in this file, you should briefly describe the models or prompts they use for all the prediction files they submit)"
   ],
   "metadata": {
    "collapsed": false,
    "id": "XgjwJprkcYQ9"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4667953b59834f77ab752acfc60f4be2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dbbdde4600a34153b25fd383a383b674",
       "IPY_MODEL_9589f99254924e65881a147d52497cc6",
       "IPY_MODEL_f61444b14d2f4791b12d885821a84d15"
      ],
      "layout": "IPY_MODEL_448d460981ba4b3ca5e8fe787a70dc58"
     }
    },
    "dbbdde4600a34153b25fd383a383b674": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c22ee51a1d549f7be198badffbb8201",
      "placeholder": "​",
      "style": "IPY_MODEL_e70d9fb027624bdc9773c1a7d4620db3",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "9589f99254924e65881a147d52497cc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_793ddd5daa2147b5bde405c8cfad62a9",
      "max": 1467,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_729be875f4fc47239fbdeb417e3145b3",
      "value": 1467
     }
    },
    "f61444b14d2f4791b12d885821a84d15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d81e0a6c994e61af6039282ac58bd2",
      "placeholder": "​",
      "style": "IPY_MODEL_0984b4dd31db444abd598882520ca385",
      "value": " 1.47k/1.47k [00:00&lt;00:00, 17.3kB/s]"
     }
    },
    "448d460981ba4b3ca5e8fe787a70dc58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c22ee51a1d549f7be198badffbb8201": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e70d9fb027624bdc9773c1a7d4620db3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "793ddd5daa2147b5bde405c8cfad62a9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "729be875f4fc47239fbdeb417e3145b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69d81e0a6c994e61af6039282ac58bd2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0984b4dd31db444abd598882520ca385": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1424933e49ca43809d1cc9a2fb364907": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d11c3ca5564c40c28a4130c5ed01363f",
       "IPY_MODEL_a638d490065c4b9c87229975429f4960",
       "IPY_MODEL_4262f208fc8148a8949641b25080efc3"
      ],
      "layout": "IPY_MODEL_b8b8c270e9f64380a01e33702b7eccdf"
     }
    },
    "d11c3ca5564c40c28a4130c5ed01363f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09b056580e1c4723b592e151ad6e7135",
      "placeholder": "​",
      "style": "IPY_MODEL_701509105ae340c9ac3afc824f9f55e7",
      "value": "tokenizer.model: 100%"
     }
    },
    "a638d490065c4b9c87229975429f4960": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76c7e443d9214295bd9f7a06a5b5c6a8",
      "max": 493443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51da62af8a1644aa8c2a121b1c6095c3",
      "value": 493443
     }
    },
    "4262f208fc8148a8949641b25080efc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a398de6f4dc409ea30f1187d32af596",
      "placeholder": "​",
      "style": "IPY_MODEL_95064a61a6174af5a927018f734e55e2",
      "value": " 493k/493k [00:00&lt;00:00, 6.55MB/s]"
     }
    },
    "b8b8c270e9f64380a01e33702b7eccdf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09b056580e1c4723b592e151ad6e7135": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "701509105ae340c9ac3afc824f9f55e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76c7e443d9214295bd9f7a06a5b5c6a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51da62af8a1644aa8c2a121b1c6095c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a398de6f4dc409ea30f1187d32af596": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95064a61a6174af5a927018f734e55e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d46898df51d14b91a5c552ecdbdc1748": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79250251f6ef43d88b6199641398bdbe",
       "IPY_MODEL_f50d293dfad2489f87943058f3800da4",
       "IPY_MODEL_c0f5136d79574cd085ca28477585fb40"
      ],
      "layout": "IPY_MODEL_a0640be91cf44e928eef22ee7e2943e9"
     }
    },
    "79250251f6ef43d88b6199641398bdbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_740320c045a346bab76b931e425d9ef3",
      "placeholder": "​",
      "style": "IPY_MODEL_20707524e7f541b0a0769113bfe777f9",
      "value": "tokenizer.json: 100%"
     }
    },
    "f50d293dfad2489f87943058f3800da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d138ebcea264ca985c126cd7586b190",
      "max": 1795303,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_796bb8d0947e48ab9ea5eab875c4adf4",
      "value": 1795303
     }
    },
    "c0f5136d79574cd085ca28477585fb40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9bd1ac7702a46c398282edf3aca89de",
      "placeholder": "​",
      "style": "IPY_MODEL_216d247520764019b60b9ce4c9218671",
      "value": " 1.80M/1.80M [00:00&lt;00:00, 12.0MB/s]"
     }
    },
    "a0640be91cf44e928eef22ee7e2943e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "740320c045a346bab76b931e425d9ef3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20707524e7f541b0a0769113bfe777f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d138ebcea264ca985c126cd7586b190": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "796bb8d0947e48ab9ea5eab875c4adf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9bd1ac7702a46c398282edf3aca89de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "216d247520764019b60b9ce4c9218671": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "244a2085543f47ae86ee53b9ce274ecb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_50e140f0a23b4dd9aebe2e5dfc4b50c6",
       "IPY_MODEL_d7a6322396064ec78aea951d0eca77d4",
       "IPY_MODEL_3bff03adfadf4eb880f92b30340de2b3"
      ],
      "layout": "IPY_MODEL_ed2ac3d94ba446dead80817cc3121a9c"
     }
    },
    "50e140f0a23b4dd9aebe2e5dfc4b50c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84fc16c60f004b58854c15544ab98dca",
      "placeholder": "​",
      "style": "IPY_MODEL_06a21b9d104648488243afec2d32d0fa",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "d7a6322396064ec78aea951d0eca77d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98ac14333666490f986962e1d749aa23",
      "max": 72,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_22c739513f6741a88ded38ed428a7842",
      "value": 72
     }
    },
    "3bff03adfadf4eb880f92b30340de2b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86543498f31c4b79a7a8717e5cd0ccf2",
      "placeholder": "​",
      "style": "IPY_MODEL_332c88ecd3b648c1bb0a691b258e0978",
      "value": " 72.0/72.0 [00:00&lt;00:00, 4.14kB/s]"
     }
    },
    "ed2ac3d94ba446dead80817cc3121a9c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84fc16c60f004b58854c15544ab98dca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06a21b9d104648488243afec2d32d0fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98ac14333666490f986962e1d749aa23": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22c739513f6741a88ded38ed428a7842": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "86543498f31c4b79a7a8717e5cd0ccf2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "332c88ecd3b648c1bb0a691b258e0978": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
